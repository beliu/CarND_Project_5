{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Import the necessary libraries and packages\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "from alexnet import AlexNet\n",
    "# from sklearn.svm import LinearSVC\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>occluded</th>\n",
       "      <th>label</th>\n",
       "      <th>attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uda_1478019952686311006.jpg</td>\n",
       "      <td>950</td>\n",
       "      <td>574</td>\n",
       "      <td>1004</td>\n",
       "      <td>620</td>\n",
       "      <td>0</td>\n",
       "      <td>car</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uda_1478019952686311006.jpg</td>\n",
       "      <td>1748</td>\n",
       "      <td>482</td>\n",
       "      <td>1818</td>\n",
       "      <td>744</td>\n",
       "      <td>0</td>\n",
       "      <td>pedestrian</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uda_1478019953180167674.jpg</td>\n",
       "      <td>872</td>\n",
       "      <td>586</td>\n",
       "      <td>926</td>\n",
       "      <td>632</td>\n",
       "      <td>0</td>\n",
       "      <td>car</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uda_1478019953689774621.jpg</td>\n",
       "      <td>686</td>\n",
       "      <td>566</td>\n",
       "      <td>728</td>\n",
       "      <td>618</td>\n",
       "      <td>1</td>\n",
       "      <td>truck</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uda_1478019953689774621.jpg</td>\n",
       "      <td>716</td>\n",
       "      <td>578</td>\n",
       "      <td>764</td>\n",
       "      <td>622</td>\n",
       "      <td>0</td>\n",
       "      <td>car</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Filename  xmin  ymin  xmax  ymax  occluded       label  \\\n",
       "0  uda_1478019952686311006.jpg   950   574  1004   620         0         car   \n",
       "1  uda_1478019952686311006.jpg  1748   482  1818   744         0  pedestrian   \n",
       "2  uda_1478019953180167674.jpg   872   586   926   632         0         car   \n",
       "3  uda_1478019953689774621.jpg   686   566   728   618         1       truck   \n",
       "4  uda_1478019953689774621.jpg   716   578   764   622         0         car   \n",
       "\n",
       "  attributes  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4        NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Create the training dataset\n",
    "## Using the Udacity Dataset\n",
    "# Read the data csv file\n",
    "udacity_df = pd.read_csv(\"../data/labels.csv\")\n",
    "\n",
    "# Check the top of the dataframe to make sure it's read in correctly\n",
    "udacity_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>occluded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>93086.000000</td>\n",
       "      <td>93086.000000</td>\n",
       "      <td>93086.000000</td>\n",
       "      <td>93086.000000</td>\n",
       "      <td>93086.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>805.390864</td>\n",
       "      <td>533.632942</td>\n",
       "      <td>936.441914</td>\n",
       "      <td>652.539243</td>\n",
       "      <td>0.426079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>448.187238</td>\n",
       "      <td>99.227053</td>\n",
       "      <td>455.023755</td>\n",
       "      <td>130.140670</td>\n",
       "      <td>0.494508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>468.000000</td>\n",
       "      <td>514.000000</td>\n",
       "      <td>598.000000</td>\n",
       "      <td>616.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>804.000000</td>\n",
       "      <td>562.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>662.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1112.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>1236.000000</td>\n",
       "      <td>706.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1896.000000</td>\n",
       "      <td>886.000000</td>\n",
       "      <td>1924.000000</td>\n",
       "      <td>1198.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               xmin          ymin          xmax          ymax      occluded\n",
       "count  93086.000000  93086.000000  93086.000000  93086.000000  93086.000000\n",
       "mean     805.390864    533.632942    936.441914    652.539243      0.426079\n",
       "std      448.187238     99.227053    455.023755    130.140670      0.494508\n",
       "min        0.000000      0.000000     16.000000     54.000000      0.000000\n",
       "25%      468.000000    514.000000    598.000000    616.000000      0.000000\n",
       "50%      804.000000    562.000000    898.000000    662.000000      0.000000\n",
       "75%     1112.000000    592.000000   1236.000000    706.000000      1.000000\n",
       "max     1896.000000    886.000000   1924.000000   1198.000000      1.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get some details about the dataset\n",
    "udacity_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93086, 5)\n",
      "[['../data/udacity_dataset/uda_1478019952686311006.jpg' 950 574 1004 620]\n",
      " ['../data/udacity_dataset/uda_1478019952686311006.jpg' 1748 482 1818 744]\n",
      " ['../data/udacity_dataset/uda_1478019953180167674.jpg' 872 586 926 632]\n",
      " ['../data/udacity_dataset/uda_1478019953689774621.jpg' 686 566 728 618]\n",
      " ['../data/udacity_dataset/uda_1478019953689774621.jpg' 716 578 764 622]\n",
      " ['../data/udacity_dataset/uda_1478019953689774621.jpg' 826 580 880 626]\n",
      " ['../data/udacity_dataset/uda_1478019953689774621.jpg' 1540 488 1680 608]\n",
      " ['../data/udacity_dataset/uda_1478019953689774621.jpg' 1646 498 1848 594]\n",
      " ['../data/udacity_dataset/uda_1478019954186238236.jpg' 662 562 710 616]\n",
      " ['../data/udacity_dataset/uda_1478019954186238236.jpg' 686 576 730 628]]\n"
     ]
    }
   ],
   "source": [
    "# Extract the filename and bounding box data from the dataframe and convert them to a numpy array\n",
    "udacity_filenames = \"../data/udacity_dataset/\" + udacity_df[\"Filename\"].values\n",
    "udacity_filenames = np.reshape(udacity_filenames, (-1, 1))\n",
    "udacity_bboxes = udacity_df[[\"xmin\", \"ymin\", \"xmax\", \"ymax\"]].values\n",
    "udacity_dataset = np.concatenate((udacity_filenames, udacity_bboxes), axis=1)\n",
    "\n",
    "print(udacity_dataset.shape)\n",
    "print(udacity_dataset[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One-hot encode the labels\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "udacity_labels = udacity_df[\"label\"].values\n",
    "encoder = LabelBinarizer()\n",
    "encoder.fit(udacity_labels)\n",
    "udacity_labels = encoder.transform(udacity_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Shuffle and split the data into a training and test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(udacity_dataset, udacity_labels, test_size=0.2, \n",
    "                                                    stratify=udacity_labels, random_state=42)\n",
    "\n",
    "# Split the training set into a training and validation set\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train, y_train, test_size=0.1,\n",
    "                                                            stratify=y_train, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67021, 5)\n",
      "(7447, 5)\n",
      "(18618, 5)\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_validate.shape)\n",
    "print(X_test.shape)\n",
    "n_classes = y_train.shape[-1]\n",
    "print(n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(X, y, batch_size):\n",
    "    '''\n",
    "        A generator that supplies batches of data to the Neural Network model\n",
    "        Parameters:\n",
    "            X: The input dataset\n",
    "            y: the labels for each row of the dataset\n",
    "            batch_size: how many rows are in each batch\n",
    "        Returns:\n",
    "            X_out: a batch, of length batch_size, of the dataset\n",
    "            y_out: the corresponding labels to the batch output\n",
    "    '''\n",
    "    for ii in range(0, len(X), batch_size):\n",
    "        X_out = []    # List for storing the extracted image array\n",
    "        for row in X[ii:ii + batch_size]:\n",
    "            # Extract the image filename and bounded box coordinates\n",
    "            file, xmin, ymin, xmax, ymax = row\n",
    "            img = mpimg.imread(file)\n",
    "            img = img[ymin:(ymax + 1), xmin:(xmax + 1)]\n",
    "            img = cv2.resize(img, (64, 64))\n",
    "            X_out.append(img)\n",
    "\n",
    "        X_out = np.array(X_out)\n",
    "        y_out = y[ii:ii + batch_size]\n",
    "\n",
    "        yield X_out, y_out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/10... batch 0/523... training loss: 0.8083...  training accuracy: 0.7734\n",
      "epoch 1/10... batch 2/523... training loss: 0.7222...  training accuracy: 0.7656\n",
      "epoch 1/10... batch 4/523... training loss: 0.3964...  training accuracy: 0.9062\n",
      "epoch 1/10... batch 6/523... training loss: 0.7313...  training accuracy: 0.7969\n",
      "epoch 1/10... batch 8/523... training loss: 0.7188...  training accuracy: 0.7891\n",
      "epoch 1/10... batch 10/523... training loss: 0.7232...  training accuracy: 0.8359\n",
      "epoch 1/10... batch 12/523... training loss: 0.3887...  training accuracy: 0.8750\n",
      "epoch 1/10... batch 14/523... training loss: 0.3659...  training accuracy: 0.8750\n",
      "epoch 1/10... batch 16/523... training loss: 0.3695...  training accuracy: 0.8672\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-79ef5c1b3429>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mii\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                 \u001b[0mtrain_accy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 print(\"epoch {}/{}... batch {}/{}...\".format(e+1, epochs, ii, n_batches),\n",
      "\u001b[0;32m~/anaconda/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \"\"\"\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3631\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3632\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 3633\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create the graph placeholders\n",
    "features = tf.placeholder(tf.float32, (None, 64, 64, 3))\n",
    "resized = tf.image.resize_images(features, (227, 227)) # AlexNet expects images of size 227 x 227\n",
    "labels = tf.placeholder(tf.int64, (None, n_classes))\n",
    "\n",
    "# Get the penultimate layer from AlexNet\n",
    "fc7 = AlexNet(resized, feature_extract=True)\n",
    "fc7 = tf.stop_gradient(fc7) # Freeze back-propagation from updating weights behind this layer\n",
    "\n",
    "# Create a new fully-connected layer for classification on this dataset\n",
    "fc8_shape = [fc7.get_shape().as_list()[-1], n_classes]\n",
    "fc8_w = tf.Variable(tf.truncated_normal(fc8_shape, stddev=1e-2), name=\"fc8_weights\")\n",
    "fc8_b = tf.Variable(tf.zeros(n_classes), name=\"fc8_biases\")\n",
    "\n",
    "logits = tf.nn.xw_plus_b(fc7, fc8_w, fc8_b, name=\"logits\")\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "opt = tf.train.AdamOptimizer().minimize(loss, var_list=[fc8_w, fc8_b])\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "accy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "save_file = \"./model.ckpt\"\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    n_batches = len(X_train) // batch_size\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        total_val_loss = 0\n",
    "        total_val_accy = 0\n",
    "        for ii, (batch_x, batch_y) in enumerate(get_batches(X_train, y_train, batch_size)):\n",
    "            feed_dict = {features: batch_x, labels: batch_y}\n",
    "            _ = sess.run(opt, feed_dict)\n",
    "\n",
    "            if ii % 2 == 0:\n",
    "                train_loss = loss.eval(feed_dict)\n",
    "                train_accy = accy.eval(feed_dict)\n",
    "                print(\"epoch {}/{}... batch {}/{}...\".format(e+1, epochs, ii, n_batches),\n",
    "                      \"training loss: {:.4f}... \".format(train_loss),\n",
    "                      \"training accuracy: {:.4f}\".format(train_accy))\n",
    "        \n",
    "        for jj, (val_batch_x, val_batch_y) in enumerate(get_batches(X_validate, y_validate, batch_size)):\n",
    "            feed_dict = {features: val_batch_x, labels: val_batch_y}\n",
    "            val_loss = loss.eval(feed_dict)\n",
    "            val_accy = accy.eval(feed_dict)\n",
    "            total_val_loss += val_loss * len(val_batch_x)\n",
    "            total_val_accy += val_accy * len(val_batch_x)\n",
    "        \n",
    "        total_val_loss = total_val_loss / len(X_validate)\n",
    "        total_val_accy = total_val_accy / len(X_validate)\n",
    "            \n",
    "        print(\"epoch {}/{}... \".format(e+1, epochs),\n",
    "              \"validaion loss: {:/4f}... \".format(total_val_loss),\n",
    "              \"validation accuracy: {:.4f}\".format(total_val_accy))\n",
    "             \n",
    "    # Save the model\n",
    "    saver.save(sess, save_file) \n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
